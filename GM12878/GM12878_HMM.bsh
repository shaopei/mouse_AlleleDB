Min_count=1
Max_Pvalus=1

#locations of pipeline
PL=/workdir/sc2457/tools/After_AlleleDB_pipeline

# only anaysis autosome now
grep -v X counts_plus.txt > counts_plus_noX.txt
grep -v X counts_minus.txt > counts_minus_noX.txt



# filter input files based on Min reads count and Max P-value
R --vanilla --slave --args $(pwd) counts_plus_noX.txt ${Min_count} ${Max_Pvalus} < ${PL}/filter_counts_file.R 
R --vanilla --slave --args $(pwd) counts_minus_noX.txt ${Min_count} ${Max_Pvalus} < ${PL}/filter_counts_file.R 

Input_counts_plus=counts_plus_noX_MinCount${Min_count}_MaxPvalue${Max_Pvalus}.txt
Input_counts_minus=counts_minus_noX_MinCount${Min_count}_MaxPvalue${Max_Pvalus}.txt

# $18 0.5 <= CNV <= 1.5
# use for hmm training
# $8 <0.038 is from allelicbias-PersonalGenome_P.CAST_M.B6-LEP_ZYG_ATGCA_forAlleleDB
head ${Input_counts_plus} -n 1 |awk 'BEGIN{OFS="\t"} {print $1,$2,$19, $20, $21, "state"}' > counts_hmm.txt 
cat ${Input_counts_plus} | \
awk 'BEGIN{OFS="\t"} ($18 <1.5 && $18 >0.5) {print $1,$2,$19, $20, $21,$14,$15,$16}' |\
awk 'BEGIN{OFS="\t"} ($8 <0.038) {print $1,$2,$3, $4, $5, $6}; ($8 >=0.038){print $1,$2,$3, $4, $5, "S"}' >> counts_hmm.txt 

cat ${Input_counts_minus} |\
awk 'BEGIN{OFS="\t"} ($18 <1.5 && $18 >0.5) {print $1,$2,$19, $20, $21,$14,$15,$16}' |\
awk 'BEGIN{OFS="\t"} ($8 <0.038) {print $1,$2,$3, $4, $5, $6}; ($8 >=0.038){print $1,$2,$3, $4, $5, "S"}' >> counts_hmm.txt 


#use for hmm prediction
#combine chromosone
head ${Input_counts_plus} -n 1 |awk 'BEGIN{OFS="\t"} {print $1,$2,$19, $20, $21, "state"}' > counts_plus_hmm.txt 
cat ${Input_counts_plus} |\
awk 'BEGIN{OFS="\t"} ($18 <1.5 && $18 >0.5) {print $1,$2,$19, $20, $21,$14,$15,$16}' |\
awk 'BEGIN{OFS="\t"} ($8 <0.038) {print $1,$2,$3, $4, $5, $6}; ($8 >=0.038){print $1,$2,$3, $4, $5, "S"}' >> counts_plus_hmm.txt 

head ${Input_counts_minus} -n 1 |awk 'BEGIN{OFS="\t"} {print $1,$2,$19, $20, $21, "state"}' > counts_minus_hmm.txt 
cat ${Input_counts_minus} |\
awk 'BEGIN{OFS="\t"} ($18 <1.5 && $18 >0.5) {print $1,$2,$19, $20, $21,$14,$15,$16}' |\
awk 'BEGIN{OFS="\t"} ($8 <0.038) {print $1,$2,$3, $4, $5, $6}; ($8 >=0.038){print $1,$2,$3, $4, $5, "S"}' >> counts_minus_hmm.txt 



##
PL=/workdir/sc2457/alleleDB/alleledb_pipeline
MAPS=/workdir/sc2457/alleleseq.gersteinlab.org/NA12878_diploid/NA12878_diploid_2015_feb5_3versions/1kgp3-svs-pass_NA12878_hg19_150109_w_transcriptome/%s_NA12878.map
PREFIX=SRR1552485_total
MATBOWTIE=${PREFIX}.mat.bowtie
PATBOWTIE=${PREFIX}.pat.bowtie
FDR_SIMS=10
FDR_CUTOFF=0.1


# remove AMB reads and sort by index
python ${PL}/filter_reads_out.py ${PATBOWTIE} - originalmatpatreads.toremove.ids | LC_ALL=C  sort -k1 -n  --parallel=30 -o ${PATBOWTIE}_AMBremoved_sorted
python ${PL}/filter_reads_out.py ${MATBOWTIE} - originalmatpatreads.toremove.ids | LC_ALL=C  sort -k1 -n  --parallel=30 -o ${MATBOWTIE}_AMBremoved_sorted

# seperate mat and pat reads from bowtie output
# order matters! ${PATBOWTIE}_AMBremoved_sorted need to be in front of ${MATBOWTIE}_AMBremoved_sorted !!!
python ${PL}/seperate_mat_pat_reads_withSNPs.py ${PATBOWTIE}_AMBremoved_sorted ${MATBOWTIE}_AMBremoved_sorted ${MAPS}
# output is ${PATBOWTIE}_AMBremoved_sorted_specific.bowtie ${PATBOWTIE}_AMBremoved_sorted_identical.bowtie ${MATBOWTIE}_AMBremoved_sorted_specific.bowtie ${MAPS}

#bowtie to bed
  INPUT (bowtie output) 
  col1: read_name              
  col2: strand
  col3: chr
  col4: position (0-based)
  col5: Read sequence (reverse-complemented if orientation is -).
  col6: ASCII-encoded read qualities (reversed if orientation is -)
  col7: 
  col8: info
  
  Convert bowtie to bed file with the 4th col the ID and sequence of the read separated by "#*o*#"
  position here is  0based
  OUTPUT is UNsorted:
  col1: chr
  col2: chromStart(0based) 
  col3: chrEnd(1based)	half open, chromStart=0, chromEnd=100, and span the bases numbered 0-99
  col4: ID#*o*#sequence#*o*#strand#*o*#score
  col5: 111
  col6: strand

#//for f in *_AMBremoved_sorted_specific.bowtie; 
#//	do cat $f | awk 'BEGIN {FS= "\t"; OFS="\t"; t="#*o*#"; H=111 } {print $3, $4, $4+length($5), $1t$5t$2t$6, $H, $2}' > $f.bed
#//done
cat ${MATBOWTIE}_AMBremoved_sorted_specific.bowtie | awk 'BEGIN {FS= "\t"; OFS="\t"; t="#*o*#"} {print $3, $4, $4+length($5), $1t$5t$2t$6, 111, $2}' > ${MATBOWTIE}_AMBremoved_sorted_specific.bed &
cat ${PATBOWTIE}_AMBremoved_sorted_specific.bowtie | awk 'BEGIN {FS= "\t"; OFS="\t"; t="#*o*#"} {print $3, $4, $4+length($5), $1t$5t$2t$6, 111, $2}' > ${PATBOWTIE}_AMBremoved_sorted_specific.bed &
cat ${PATBOWTIE}_AMBremoved_sorted_identical.bowtie| awk 'BEGIN {FS= "\t"; OFS="\t"; t="#*o*#"} {print $3, $4, $4+length($5), $1t$5t$2t$6, 111, $2}' > ${PATBOWTIE}_AMBremoved_sorted_identical.bed &
wait

# liftOver to reference genome
# usage: liftOver oldFile map.chain newFile unMapped
liftOver ${MATBOWTIE}_AMBremoved_sorted_specific.bed mat2ref.chain  ${MATBOWTIE}_AMBremoved_sorted_specific.map2ref.bed ${MATBOWTIE}_AMBremoved_sorted_specific.unmap2ref.log
liftOver ${PATBOWTIE}_AMBremoved_sorted_specific.bed pat2ref.chain  ${PATBOWTIE}_AMBremoved_sorted_specific.map2ref.bed ${PATBOWTIE}_AMBremoved_sorted_specific.unmap2ref.log
liftOver ${PATBOWTIE}_AMBremoved_sorted_identical.bed pat2ref.chain  ${PATBOWTIE}_AMBremoved_sorted_identical.map2ref.bed ${PATBOWTIE}_AMBremoved_sorted_identical.unmap2ref.log


cat ${PATBOWTIE}_AMBremoved_sorted_identical.map2ref.bed | LC_ALL=C sort -k1,1V -k2,2n --parallel=30 |awk '{print "chr"$0}' > ${PATBOWTIE}_AMBremoved_sorted_identical.map2ref.sorted.bed &

# remove reads that DONOT overlape with a SNP in ${PATBOWTIE}_AMBremoved_sorted_specific.map2ref.sorted.bed and  ${MATBOWTIE}_AMBremoved_sorted_specific.map2ref.sorted.bed 
intersectBed -sorted -u -a <(LC_ALL=C sort -k1,1V -k2,2n --parallel=30 ${MATBOWTIE}_AMBremoved_sorted_specific.map2ref.bed |awk '{print "chr"$0}') \
-b /workdir/sc2457/SNP/1000genome_vol1.ftp.release.20130502/snp.calls.bed > ${MATBOWTIE}_AMBremoved_sorted_specific.map2ref.sorted.bed &
intersectBed -sorted -u -a <(LC_ALL=C sort -k1,1V -k2,2n --parallel=30 ${PATBOWTIE}_AMBremoved_sorted_specific.map2ref.bed |awk '{print "chr"$0}') \
-b /workdir/sc2457/SNP/1000genome_vol1.ftp.release.20130502/snp.calls.bed > ${PATBOWTIE}_AMBremoved_sorted_specific.map2ref.sorted.bed &


# ln -s /workdir/sc2457/mouse_AlleleSpecific/allelicbias-PersonalGenome_P.CAST_M.B6-LEP_ZYG_ATGCA_forAlleleDB/Tm_Tp_fixed_redo/hmm_spc.py .

python hmm_spc.py counts_hmm.txt counts_plus_hmm.txt counts_minus_hmm.txt 22

ln -s /workdir/sc2457/mouse_AlleleSpecific/allelicbias-PersonalGenome_P.CAST_M.B6-LEP_ZYG_ATGCA_forAlleleDB/Tm_Tp_fixed_redo/sum_of_counts.py .
ln -s /workdir/sc2457/mouse_AlleleSpecific/allelicbias-PersonalGenome_P.CAST_M.B6-LEP_ZYG_ATGCA_forAlleleDB/Tm_Tp_fixed_redo/getFractionOfBlock_DistanceToNearestSites.R .
ln -s /workdir/sc2457/tools/After_AlleleDB_pipeline/tss_paired_gm12878_plus.bed .
ln -s /workdir/sc2457/tools/After_AlleleDB_pipeline/tss_paired_gm12878_minus.bed .

### counts the maternal, paternal reads, and the reads that cannot tell where it from, in the regions of hmm predictions
# perform BinomialTest and filter by FDR<= FDR_CUTOFF
for s in plus minus
  do for T in {1..9}
  do f=counts_${s}_hmm_regions_t1e-0${T}.bed ; j=counts_${s}_hmm_regions_t1e-0${T}
bedtools coverage -a <(cat $f | awk '{print "chr"$0}') -b ${MATBOWTIE}_AMBremoved_sorted_specific.map2ref.sorted.bed -s | awk 'BEGIN {OFS="\t"; t="_"} {print $1t$2t$3, $0}' |LC_ALL=C sort -k1,1 --parallel=30 > ${j}.mat_cov.bed &
bedtools coverage -a <(cat $f | awk '{print "chr"$0}') -b ${PATBOWTIE}_AMBremoved_sorted_specific.map2ref.sorted.bed -s | awk 'BEGIN {OFS="\t"; t="_"} {print $1t$2t$3, $0}' |LC_ALL=C sort -k1,1 --parallel=30 > ${j}.pat_cov.bed &
wait
join -t $'\t' -j 1 -o 1.1,1.2,1.3,1.4,1.5,1.8,2.8 ${j}.mat_cov.bed ${j}.pat_cov.bed > ${j}.temp_cov.bed &
bedtools coverage -a <(cat $f | awk '{print "chr"$0}') -b ${PATBOWTIE}_AMBremoved_sorted_identical.map2ref.sorted.bed -s | awk 'BEGIN {OFS="\t"; t="_"} {print $1t$2t$3, $0}' |LC_ALL=C sort -k1,1 --parallel=30 > ${j}.iden_cov.bed &
wait
join -t $'\t' -j 1 -o 1.2,1.3,1.4,1.5,1.6,1.7,2.8 ${j}.temp_cov.bed ${j}.iden_cov.bed | LC_ALL=C sort -k1,1V -k2,2n --parallel=30 > ${j}.merged_cov.bed
rm ${j}.temp_cov.bed ${j}.mat_cov.bed ${j}.pat_cov.bed ${j}.iden_cov.bed
python ${PL}/BinomialTestFor_merged_cov.bed.py ${j}.merged_cov.bed ${j}.merged_cov_binomtest.bed
rm ${j}.merged_cov.bed

# output of BinomialTestFor_merged_cov.bed.py:(hmm+BinomialTest) if p-value <= 0.05, remain what it got from hmm (can ne M,P, or S), otherwise S.
python ${PL}/FalsePosFor_merged_cov.bed.py ${j}.merged_cov_binomtest.bed ${FDR_SIMS} ${FDR_CUTOFF} > ${j}.merged_cov_binomtest_FDR.txt
awk 'NR==1 { print $0 } NR>1 && $9 <= thresh { print $0 }'  thresh=$(awk 'END {print $6}' ${j}.merged_cov_binomtest_FDR.txt) < ${j}.merged_cov_binomtest.bed > ${j}_interestingHets.bed &
done
done
wait


### make bed with only the 5prime head reads
for f in counts_*_hmm_regions_t*_interestingHets.bed;
  do echo $f
j=`echo $f| rev | cut -d \. -f 2- |rev |cut -d _ -f 3-`
strand=`echo $f|cut -d _ -f 2`
echo $strand $j
# filter and only keep M and P, use the state from hmm(hmm_state, Not hmm+BinomialTest ), which binomial test pass FDR <0.1
if [ ${strand} == "minus" ]
then cat counts_minus_${j}.bed | awk 'BEGIN {OFS="\t"; t=","; s="-";c="chr"} NR==1 { print $1,$2,$3,$4t$6t$7, 111, s} 
NR>1 && $4!="S" {print $1,$3-1,$3,$4t$6t$7, 111, s}' > counts_minus_${j}_5head.bed
bedtools closest -D a -a <(cat counts_minus_${j}_5head.bed | awk 'BEGIN {OFS="\t"} NR!=1 {print $0}' | LC_ALL=C sort -k1,1 -k2,2n --parallel=30) -b tss_paired_gm12878_minus.bed \
|awk '($NF<0){print $NF*(-1)}; ($NF>=0) {print $NF}' > counts_${j}_5head_distance_toclosest-dReg_Counts.tmp

else
cat counts_plus_${j}.bed | awk 'BEGIN {OFS="\t"; t=","; s="+";c="chr"} NR==1 { print $1,$2,$3,$4t$6t$7, 111, s} 
NR>1 && $4!="S"  {print $1,$2,$2+1,$4t$6t$7, 111, s}' > counts_plus_${j}_5head.bed
bedtools closest -D a -a <(cat counts_plus_${j}_5head.bed | awk 'BEGIN {OFS="\t"} NR!=1 {print $0}' | LC_ALL=C sort -k1,1 -k2,2n --parallel=30) -b tss_paired_gm12878_plus.bed \
|awk '($NF<0){print $NF*(-1)}; ($NF>=0) {print $NF}' >>  counts_${j}_5head_distance_toclosest-dReg_Counts.tmp
fi
cat counts_${j}_5head_distance_toclosest-dReg_Counts.tmp | LC_ALL=C sort --temporary-directory=/workdir/sc2457/tmp/ --parallel=10 -n | uniq -c > counts_${j}_5head_distance_toclosest-dReg_Counts.txt
#rm counts_${j}_5head_distance_toclosest-dReg_Counts.tmp

# distance to the closet upstream dReg sites.
# -D a Report distance with respect to A.
# -id Ignore features in B that are downstream of features in A. 
# check both end, no id
#bedtools closest -D a -a <(cat counts_${j}_5head.bed | awk 'BEGIN {OFS="\t"} NR!=1 {print $0}' | LC_ALL=C sort -k1,1 -k2,2n --parallel=30) -b LEP_ZYG_ATGCA.dREG.peak.score.bed.gz \
#|awk '($13<0){print $13*(-1)}; ($13>=0) {print $13}' | LC_ALL=C sort --temporary-directory=/workdir/sc2457/tmp/ --parallel=10 -n | uniq -c >  counts_${j}_5head_distance_toclosest-dReg_Counts.txt

python sum_of_counts.py counts_${j}_5head_distance_toclosest-dReg_Counts.txt `awk 'END {print $2}' counts_${j}_5head_distance_toclosest-dReg_Counts.txt` > counts_${j}_5head_distance_toclosest-dReg_AccumulateCounts.txt 

done


### make figures
R --vanilla --slave --args $(pwd) "counts_hmm_regions_t*_interestingHets_5head_distance_toclosest-dReg_AccumulateCounts.txt" counts_hmm_regions_tX_interestingHets_5head_distance_toclosest-dReg_AccumulateCounts.pdf counts_hmm_regions_tX_interestingHets_5head_distance_toclosest-dReg_At5Kb.pdf < getFractionOfBlock_DistanceToNearestSites.R
# pick t1e-06 for GM12878

####END of analysis ######

#### find concordant and discordant regions
# keep fdr <= 0.1 and state is P or M, 
# this can also used for IGV viewing
T=5
cat counts_minus_hmm_regions_t1e-0${T}_interestingHets.bed | awk 'BEGIN {OFS="\t"; t=","; s="-";c="chr"} NR==1 { print $1,$2,$3,$4t$6t$7, 111, s} 
NR>1 && $4!="S"  {print $1,$2,$3,$4t$6t$7, 111, s}' > counts_minus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed

cat counts_plus_hmm_regions_t1e-0${T}_interestingHets.bed | awk 'BEGIN {OFS="\t"; t=","; s="+";c="chr"} NR==1 { print $1,$2,$3,$4t$6t$7, 111, s} 
NR>1 && $4!="S"  {print $1,$2,$3,$4t$6t$7, 111, s}' > counts_plus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed

cat counts_minus_hmm_regions_t1e-0${T}.merged_cov_binomtest.bed | awk 'BEGIN {OFS="\t"; t=","; s="-"} NR==1 { print $1,$2,$3,$4t$6t$7, 111, s} 
NR>1  {print $1,$2,$3,$4t$6t$7, 111, s}' > counts_minus_hmm_regions_t1e-0${T}.merged_cov_binomtest_IGV.bed
cat counts_plus_hmm_regions_t1e-0${T}.merged_cov_binomtest.bed | awk 'BEGIN {OFS="\t"; t=","; s="+"} NR==1 { print $1,$2,$3,$4t$6t$7, 111, s} 
NR>1  {print $1,$2,$3,$4t$6t$7, 111, s}' > counts_plus_hmm_regions_t1e-0${T}.merged_cov_binomtest_IGV.bed


counts_plus_hmm_regions_t1e-05.merged_cov_binomtest.bed

# identify regions intersect with tss +- 150bp
## sort Tss regions, only need to do once
#cat tss_paired_gm12878_plus.bed |LC_ALL=C sort --temporary-directory=/workdir/sc2457/tmp/ --parallel=10 -V |awk '{OFS="\t"} {print $1,$2,$3,$4,NR,$6}' > tss_paired_gm12878_plus_Vsorted.bed
#cat tss_paired_gm12878_minus.bed |LC_ALL=C sort --temporary-directory=/workdir/sc2457/tmp/ --parallel=10 -V |awk '{OFS="\t"} {print $1,$2,$3,$4,NR,$6}'> tss_paired_gm12878_minus_Vsorted.bed


T=5
#paste <(bedtools closest -iu -D a -a tss_paired_gm12878_plus_Vsorted.bed -b counts_plus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed) <(bedtools closest -iu -D a -a tss_paired_gm12878_minus_Vsorted.bed -b counts_minus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed) \
#|awk '($13 != -1 && $NF !=-1 && $13<=150 && $NF<=150) {print substr($10,1,1), substr($23,1,1)}' | awk '($1 == $2){print $0} '
# Concordant 
join -t $'\t' -j 5 -o 1.1,1.2,1.3,1.10,1.13,2.1,2.2,2.3,2.10,2.13 <(bedtools closest -iu -D a -a tss_paired_gm12878_plus_Vsorted.bed -b counts_plus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed) <(bedtools closest -iu -D a -a tss_paired_gm12878_minus_Vsorted.bed -b counts_minus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed) |awk '($5 != -1 && $10 !=-1 && $5<=150 && $10<=150) {print $0}' | awk '(substr($4,1,1) == substr($9,1,1)){print $0} ' | wc -l
# Discordant 
join -t $'\t' -j 5 -o 1.1,1.2,1.3,1.10,1.13,2.1,2.2,2.3,2.10,2.13 <(bedtools closest -iu -D a -a tss_paired_gm12878_plus_Vsorted.bed -b counts_plus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed) <(bedtools closest -iu -D a -a tss_paired_gm12878_minus_Vsorted.bed -b counts_minus_hmm_regions_t1e-0${T}_interestingHets_IGV.bed) |awk '($5 != -1 && $10 !=-1 && $5<=150 && $10<=150) {print $0}' | awk '(substr($4,1,1) != substr($9,1,1)){print $0} ' | wc -l




bedtools closest -D a -a <(cat counts_plus_${j}_5head.bed | awk 'BEGIN {OFS="\t"} NR!=1 {print $0}' | LC_ALL=C sort -k1,1 -k2,2n --parallel=30) -b tss_paired_gm12878_plus.bed \
|awk '($13<0){print $13*(-1)}; ($13>=0) {print $13}' >>  counts_${j}_5head_distance_toclosest-dReg_Counts.tmp






 